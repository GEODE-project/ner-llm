{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token classification with Ollama\n",
    "\n",
    "PAGODA platform at LIRIS.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from ollama_instructor import OllamaInstructor\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import filter_ner_io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"GEODE/GeoEDdA\")\n",
    "dfs = []\n",
    "for key in dataset.keys():\n",
    "    dfs.append(pd.DataFrame({'dataset':key, 'text':dataset[key]['text'], 'meta':dataset[key]['meta'], 'tokens':dataset[key]['tokens'], 'spans':dataset[key]['spans']}))\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "tagset = ['Domain-mark','Head','NC-Person','NC-Spatial','NP-Misc','NP-Person','NP-Spatial','Relation','Latlong', 'ENE-Spatial', 'ENE-Person', 'ENE-Misc']\n",
    "\n",
    "df['ner_io'] = df.apply(lambda x: filter_ner_io(x, tagset), axis=1)\n",
    "\n",
    "df_train = df[df['dataset']=='train'].reset_index(drop = True)\n",
    "df_val = df[df['dataset']=='validation'].reset_index(drop = True)\n",
    "df_test = df[df['dataset']=='test'].reset_index(drop = True)\n",
    "\n",
    "examples_set_train = []\n",
    "for index,row in df_train.iterrows():\n",
    "    flat_curr=[element for elements in row['ner_io'] for element in elements]\n",
    "    examples_set_train.append(len(set(flat_curr)))\n",
    "\n",
    "idx = np.flip(np.argsort(examples_set_train))[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data structure\n",
    "class Token(BaseModel):\n",
    "    text: str = Field(description=\"Texte du token appartenant (ex : 'ville', 'France')\")\n",
    "    #label return a list of labels\n",
    "    labels: List[str] = Field(description=\"Liste des labels du token (ex : ['O'], ['Domain-mark'], ['NP-Spatial', 'ENE-Spatial'])\")\n",
    "    #label: str = Field(description=\"Label de l'entité, exclusivement parmi la liste suivante : ['Domain-mark', 'Head', 'NC-Person', 'NC-Spatial', 'NP-Misc', 'NP-Person', 'NP-Spatial', 'Relation','Latlong', 'ENE-Spatial', 'ENE-Person', 'ENE-Misc','O'] \")\n",
    "\n",
    "class Tokens(BaseModel):\n",
    "    entities: List[Token] = Field(description=\"The token contained in the provided context\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "examples=f'''Voici quelques exemples d'entrées et de sorties attendues pour la tâche d'identification des entités dans un texte :\n",
    "EXEMPLE 0:\n",
    "    INPUT:{' '.join([\"('\"+token['text']+\"' ,\"+str(id)+\")\" for id,token in enumerate(df_train.iloc[idx[1]]['tokens'])])}\n",
    "    OUTPUT:{[{'label':tag,'text':token['text']} for tag,token in zip(df_train.iloc[idx[1]]['ner_io'],df_train.iloc[idx[1]]['tokens'])]}\n",
    "---\n",
    "'''\n",
    "\n",
    "directives=f'''\n",
    "Tu es un expert en Traitement Automatique du Langage Naturel. Ta tâche est de classer chaque token pour identifier les entités (entités nommées, entités nominales et entités imbriquées) dans un texte donné. Les textes sont des paragraphes issus d'articles de l'enyclopédie de Diderot et d'Alembert, et les entités sont des tokens qui peuvent être des noms propres, des noms communs, des relations spatiales ou des coordonnées géographiques.\n",
    "Les types d'entités possibles sont exclusivement : (Domain-mark, Head, NC-Person, NC-Spatial, NP-Misc, NP-Person, NP-Spatial, Relation, Latlong, ENE-Spatial, ENE-Person, ENE-Misc, O) et peuvent être décrits comme suit :\n",
    "1. Domain-mark : token indiquant le domaine de connaissance (généralement après le head et entre parenthèses). Par exemple : 'Géog., Géog. mod., Géog. anc., Géogr., Géogr. mod., Marine., Hist. nat., Gram., Géogr. anc., Jurisprud., Géog. anc. & mod., Gramm., Geog.'\n",
    "2. Head : nom de l'entrée ou article encyclopédique au début de la phrase et est presque toujours en majuscules tel que 'Aire, Afrique, Aigle, ILLESCAS, MULHAUSEN, ADDA, SINTRA ou CINTRA, ACHSTEDE, ou AKSTEDE, KEITH, CAÇERES, CARMAGNOLE, AGRIGNON, INSPRUCK'\n",
    "3. NC-Person : un nom commun qui identifie une personne telle que 'M., roi, S., peuples, l'empereur, son fils, les habitans, prince, peuple, le roi, fils, le P., habitans'\n",
    "4. NC-Spatial : un nom commun qui identifie une entité spatiale y compris les caractéristiques naturelles telles que 'ville, petite ville, la riviere, la mer, royaume, la province, capitale, la ville, l'île, cette ville, pays, la côte, riviere'\n",
    "5. NP-Misc : un nom propre identifiant des entités non classées comme spatiales ou personnelles telles que 'l'Eglise, grec, 1707, russien, Glaciale, Noire, romain, la Croix, Russien, Parlement, 1693, Sud, 1614'\n",
    "6. NP-Person : un nom propre identifiant le nom d'une personne (entités nommées de personnes) telles que 'Ptolomée, Pline, Strabon, Euripide, les Romains, Pierre, Romains, les Anglois, Turcs, Dieu, César, Antonin, les Espagnols'\n",
    "7. NP-Spatial : un nom propre identifiant le nom d'un lieu (entités nommées spatiales) telles que 'France, Allemagne, Italie, Espagne, Afrique, Asie, Paris, Naples, Angleterre, Rome, Russie, la Chine, l'Amérique méridionale'\n",
    "8. Relation : relation spatiale telle que 'dans, sur, au, en, entre, près de, se jette dans, proche, par, vers, près du, jusqu'à, à l'orient'.\n",
    "9. Latlong : coordonnées géographiques telles que 'Long. 31. 58. lat. 40. 55', 'Long. 10. 27. lat. 43. 30', 'Long. selon Harris, 29. 16. 15. lat. 47. 15'.\n",
    "10. ENE-Spatial : entité nommée spatiale imbriquée, qui est une entité spatiale qui est composé par d'autres entités, par exemple 'la ville de Paris', 'la province de Bretagne', 'ville de France'.\n",
    "11. ENE-Person : entité nommée personne imbriquée, qui est une entité faisant référence à une personne et est composé par d'autres entités, par exemple 'le czar Pierre', 'roi de Macédoine'.\n",
    "12. ENE-Misc : entité nommée non spatiale ou personne imbriquée, qui est une entité faisant référence à un nom propre et est composé par d'autres entités, par exemple \"l'ordre de S. Jacques\", 'la déclaration du 21 Mars 1671'.\n",
    "10. O : ce token n'appartient à aucune entité.\n",
    "Chaque token de l'input doit être classé dans une ou plusieurs de ces catégories. Si un token n'appartient à aucune catégorie, il doit être classé comme 'O'.\n",
    "\n",
    "{examples}\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ollama(user_prompt, client, model_name, data_model, max_retries=3):\n",
    "\n",
    "    response = client.chat_completion(\n",
    "        format=data_model,\n",
    "        model=model_name,\n",
    "        retries=max_retries,\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': user_prompt\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return Tokens(**json.loads(response.message.content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entities=[Token(text='ILLESCAS', labels=['NP-Spatial']), Token(text=',', labels=['PONCTUATION']), Token(text='(', labels=['PONCTUATION']), Token(text='Géog', labels=['TYPE_ENTITE']), Token(text='.', labels=['PONCTUATION']), Token(text=')', labels=['PONCTUATION']), Token(text='petite', labels=['ADJECTIF']), Token(text='ville', labels=['NOM_COMMUN']), Token(text=\"d'\", labels=['PRÉPOSITION']), Token(text='Espagne', labels=['NP-Spatial']), Token(text=',', labels=['PONCTUATION']), Token(text='dans', labels=['PRÉPOSITION']), Token(text='la', labels=['ARTICLE_DEFINI']), Token(text='nouvelle', labels=['ADJECTIF']), Token(text='Castille', labels=['NP-Spatial']), Token(text=',', labels=['PONCTUATION']), Token(text='à', labels=['PRÉPOSITION']), Token(text='six', labels=['NOMBRE']), Token(text='lieues', labels=['UNITÉ_DE_MESURE']), Token(text='au', labels=['PRÉPOSITION']), Token(text='sud', labels=['DIRECTION']), Token(text='de', labels=['PRÉPOSITION']), Token(text='Madrid', labels=['NP-Spatial']), Token(text='.', labels=['PONCTUATION'])]\n"
     ]
    }
   ],
   "source": [
    "PAGODA_API_KEY = os.getenv('PAGODA_API_KEY')\n",
    "\n",
    "client = OllamaInstructor(\n",
    "    host='https://ollama-ui.pagoda.liris.cnrs.fr/ollama',\n",
    "    headers={'Authorization': f'Bearer {PAGODA_API_KEY}'}\n",
    "    )\n",
    "\n",
    "version = 'llama3_70b'\n",
    "model_name = 'llama3:70b'\n",
    "data_model = Tokens\n",
    "\n",
    "output_path = os.path.join('predictions', 'token_classification_' + version)\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "input =  f'''INPUT: {' '.join([\"('\" + token['text'] + \"' ,\" + str(id) + \")\" for id, token in enumerate(df_train.iloc[0]['tokens'])])}'''\n",
    "user_prompt = directives + input\n",
    "\n",
    "response = run_ollama(user_prompt, client, model_name, Tokens)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ILLESCAS ['NP-Spatial']\n",
      ", ['PONCTUATION']\n",
      "( ['PONCTUATION']\n",
      "Géog ['TYPE_ENTITE']\n",
      ". ['PONCTUATION']\n",
      ") ['PONCTUATION']\n",
      "petite ['ADJECTIF']\n",
      "ville ['NOM_COMMUN']\n",
      "d' ['PRÉPOSITION']\n",
      "Espagne ['NP-Spatial']\n",
      ", ['PONCTUATION']\n",
      "dans ['PRÉPOSITION']\n",
      "la ['ARTICLE_DEFINI']\n",
      "nouvelle ['ADJECTIF']\n",
      "Castille ['NP-Spatial']\n",
      ", ['PONCTUATION']\n",
      "à ['PRÉPOSITION']\n",
      "six ['NOMBRE']\n",
      "lieues ['UNITÉ_DE_MESURE']\n",
      "au ['PRÉPOSITION']\n",
      "sud ['DIRECTION']\n",
      "de ['PRÉPOSITION']\n",
      "Madrid ['NP-Spatial']\n",
      ". ['PONCTUATION']\n"
     ]
    }
   ],
   "source": [
    "for ent in response.entities:\n",
    "    print(ent.text, ent.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ner-llm-py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
