{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token classification with OpenAI GPT models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"GEODE/GeoEDdA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for key in dataset.keys():\n",
    "    dfs.append(pd.DataFrame({'dataset':key, 'text':dataset[key]['text'], 'meta':dataset[key]['meta'], 'tokens':dataset[key]['tokens'], 'spans':dataset[key]['spans']}))\n",
    "df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_ner_io(sentence, tagset):\n",
    "    result=['O']*len(sentence['tokens'])\n",
    "    for span in sentence['spans']:\n",
    "        if(span['label'] in tagset):\n",
    "            for i in range(span['token_start'],span['token_end']+1):\n",
    "                if(result[i]=='O' or span['label']=='Latlong'):\n",
    "                    result[i]=span['label']\n",
    "                elif(result[i]==['Latlong']):\n",
    "                    break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagset = ['Domain-mark','Head','NC-Person','NC-Spatial','NP-Misc','NP-Person','NP-Spatial','Relation','Latlong']\n",
    "\n",
    "df['ner_io'] = df.apply(lambda x: filter_ner_io(x, tagset), axis=1)\n",
    "\n",
    "df_train = df[df['dataset']=='train'].reset_index(drop = True)\n",
    "df_val = df[df['dataset']=='validation'].reset_index(drop = True)\n",
    "df_test = df[df['dataset']=='test'].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_set_train = []\n",
    "for index,row in df_train.iterrows():\n",
    "    flat_curr=[element for elements in row['ner_io'] for element in elements]\n",
    "    examples_set_train.append(len(set(flat_curr)))\n",
    "\n",
    "idx = np.flip(np.argsort(examples_set_train))[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data structure\n",
    "class Entity(BaseModel):\n",
    "    text: str = Field(description=\"Text of the token containing the entity such as 'ville'\")\n",
    "    label: str = Field(description=\"Label of Entity contained in the text and are exclusively: ['Domain-mark', 'Head', 'NC-Person', 'NC-Spatial', 'NP-Misc', 'NP-Person', 'NP-Spatial', 'Relation','Latlong','O'] \")\n",
    "\n",
    "class Entities(BaseModel):\n",
    "    entities: List[Entity] = Field(description=\"The token contained in the provided context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples=f'''Here are some examples:\n",
    "EXAMPLE 1:\n",
    "    INPUT:{' '.join([\"('\"+token['text']+\"' ,\"+str(id)+\")\" for id,token in enumerate(df_train.iloc[idx[1]]['tokens'])])}\n",
    "    OUTPUT:{[{'label':tag,'text':token['text']} for tag,token in zip(df_train.iloc[idx[1]]['ner_io'],df_train.iloc[idx[1]]['tokens'])]}\n",
    "---\n",
    "'''\n",
    "\n",
    "directives=f'''\n",
    "You are an expert in Natural Language Processing. Your task is to identify common Named Entities (NER) in a given text.\n",
    "The possible common Named Entities (NER) types are exclusively: (Domain-mark, Head, NC-Person, NC-Spatial, NP-Misc, NP-Person, NP-Spatial, Relation, O) and can be described as :\n",
    "1.Domain-mark: words indicating the knowledge domain (usually after the head and between parenthesis) such as 'Géog., Géog. mod., Géog. anc., Géogr., Géogr. mod., Marine., Hist. nat., Gram., Géogr. anc., Jurisprud., Géog. anc. & mod., Gramm., Geog.'\n",
    "2.Head: entry name at the beginning of the sentence and is almost always in uppercase such as 'Aire, Afrique, Aigle, ILLESCAS, MULHAUSEN, ADDA, SINTRA ou CINTRA, ACHSTEDE, ou AKSTEDE, KEITH, CAÇERES, CARMAGNOLE, AGRIGNON, INSPRUCK'\n",
    "3.NC-Person: a common noun that identifies a person such as 'M., roi, S., peuples, l'empereur, son fils, les habitans, prince, peuple, le roi, fils, le P., habitans'\n",
    "4.NC-Spatial: a common noun that identifies a spatial entity including natural features such as 'ville, petite ville, la riviere, la mer, royaume, la province, capitale, la ville, l'île, cette ville, pays, la côte, riviere'\n",
    "5.NP-Misc: a proper noun identifying entities not classified as spatial or person such as 'l'Eglise, grec, 1707, russien, Glaciale, Noire, romain, la Croix, Russien, Parlement, 1693, Sud, 1614'\n",
    "6.NP-Person: a proper noun identifying the name of a person (person named entities) such as 'Ptolomée, Pline, Strabon, Euripide, les Romains, Pierre, Romains, les Anglois, Turcs, Dieu, César, Antonin, les Espagnols'\n",
    "7.NP-Spatial: a proper noun identifying the name of a place (spatial named entities) such as 'France, Allemagne, Italie, Espagne, Afrique, Asie, Paris, Naples, Angleterre, Rome, Russie, la Chine, l'Amérique méridionale'\n",
    "8.Relation: spatial relation such as 'dans, sur, au, en, entre, près de, se jette dans, proche, par, vers, près du, jusqu'à, à l'orient'.\n",
    "9.Latlong: geographic coordinates such as 'Long. 31. 58. lat. 40. 55, Long. 10. 27. lat. 43. 30, Long. 28. 14. lat. 51. 13, Long. 14. 46. lat. 56. 20, Long. 12. 8. lat. 39. 15, Long. 25. 20. lat. 44. 43, Lat. 19. 40, Long. selon Harris, 29. 16. 15. lat. 47. 15, Long. 14. 28. lat : 53. 50, Long. 57. lat. 38. 35, Long. 22. 52. lat. 43. 32, Long. 11. 18. lat. 40. 41, Long. 27. 40. lat. 51. 50'.\n",
    "10.O: no entities are for this token\n",
    "{examples}\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gpt(model, input, directives):\n",
    "    context = f'''{' '.join([\"('\" + token['text'] + \"' ,\" + str(id) + \")\" for id, token in enumerate(input)])}'''\n",
    "    #print(context)\n",
    "    template = f'''context:{context}\n",
    "    query:{{query}}\n",
    "    format_instructions:{{format_instructions}}\n",
    "    '''\n",
    "    # Set up a parser + inject instructions into the prompt template.\n",
    "    parser = JsonOutputParser(pydantic_object=Entities)\n",
    "    prompt = PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=[\"query\"],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "    )\n",
    "    chain = prompt | model | parser\n",
    "    return chain.invoke({\"query\": directives})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'o1-mini' # 'gpt3.5', 'gpt4', 'gpt4o', 'o1-mini'\n",
    "model_name = 'o1-mini-2024-09-12' #'gpt-3.5-turbo', 'gpt-4', 'gpt-4o-mini-2024-07-18', 'gpt-4o', 'o1-preview', 'o1-mini-2024-09-12'\n",
    "\n",
    "model = ChatOpenAI(temperature=1, model=model_name)\n",
    "nb_iterations = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model with the first entry of the test set and check the output\n",
    "#run_gpt(model, df_test.iloc[0]['tokens'], directives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join('predictions', 'token_classification_' + version)\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = range(0, len(df_test.index))\n",
    "for i in range(nb_iterations):\n",
    "    pred_sentences = []\n",
    "    for j in tqdm(index):\n",
    "        try:\n",
    "            output = run_gpt(model, df_test.iloc[j]['tokens'], directives)\n",
    "            pred_sentences.append(output)\n",
    "        except Exception as e:\n",
    "            print(f\"Error for index {j}: {e}\")\n",
    "            pred_sentences.append({'entities':[]})\n",
    "    \n",
    "        with open(os.path.join(output_path,\"run_\" + str(i+1) + \".json\"), \"w\") as file:\n",
    "            json.dump(pred_sentences, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ner-llm-py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
